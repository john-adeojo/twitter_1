{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f1a1557-c590-424b-889b-8757508deb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7696be6-0b6a-4cc2-aa42-60e56b4193fe",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e8091bb-be1c-4af2-afc7-23818b0d42a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20048 entries, 0 to 20047\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   unit_id                20048 non-null  int64 \n",
      " 1   gender                 19949 non-null  object\n",
      " 2   created                20048 non-null  object\n",
      " 3   user_description       16304 non-null  object\n",
      " 4   user_favourite_number  20048 non-null  int64 \n",
      " 5   link_color             20048 non-null  object\n",
      " 6   name                   20048 non-null  object\n",
      " 7   profileimage           20048 non-null  object\n",
      " 8   retweet_count          20048 non-null  int64 \n",
      " 9   sidebar_color          20048 non-null  object\n",
      " 10  tweet_text             20048 non-null  object\n",
      " 11  tweet_coord            159 non-null    object\n",
      " 12  tweet_count            20048 non-null  int64 \n",
      " 13  tweet_location         12564 non-null  object\n",
      " 14  user_timezone          12250 non-null  object\n",
      "dtypes: int64(4), object(11)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\johna\\anaconda3\\envs\\twitter-env-1\\Data\\For Candidate - Data Scientist Role\\twitter_data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a950dc0e-a6ff-435e-bc92-33cf1a254f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca65052700cf48ec97f5fa00e69a0351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cead35946da84a709c16f8313e11a9ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53443b27d1d40f18e95043b9b1e0f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "751652ef8fcd40ea8334b589f465d7ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profile = ProfileReport(df, title=\"Twitter Profiling Report\")\n",
    "profile.to_file(r\"C:\\Users\\johna\\anaconda3\\envs\\twitter-env-1\\Reports\\twitter profile report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df26c1a7-4923-4189-8ca0-981d547afe1c",
   "metadata": {},
   "source": [
    "# Data Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b1e443b-7f4a-4469-8cf3-be52222a27b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class DataProcessor:\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "    \n",
    "    def drop_unknown_users(self):\n",
    "        self.df = self.df[self.df['gender'] != 'unknown']\n",
    "        #self.df[\"gender\"] = self.df['gender'].astype(\"category\")\n",
    "    \n",
    "    def replace_blank_user_description(self):\n",
    "        self.df['user_description'] = self.df['user_description'].fillna('no user description')\n",
    "\n",
    "        \n",
    "    def drop_columns(self, columns_to_drop):\n",
    "        self.df = self.df.drop(columns=columns_to_drop)\n",
    "        \n",
    "    def isolate_duplicates(self):\n",
    "        duplicate_names = self.df[self.df.duplicated('name')]['name']\n",
    "        self.duplicates = self.df[self.df['name'].isin(duplicate_names)]\n",
    "        self.df = self.df[~self.df['name'].isin(duplicate_names)]\n",
    "    \n",
    "    def split_data(self):\n",
    "        # Split into train, validation, and test sets\n",
    "        train_pct = 0.7\n",
    "        val_pct = 0.15\n",
    "        test_pct = 0.15\n",
    "\n",
    "        # Set random seed for reproducibility\n",
    "        np.random.seed(42)\n",
    "\n",
    "        # Shuffle the data\n",
    "        shuffled_df = self.df.sample(frac=1)\n",
    "\n",
    "        # Determine the number of rows for each set\n",
    "        num_rows = len(shuffled_df)\n",
    "        train_rows = int(num_rows * train_pct)\n",
    "        val_rows = int(num_rows * val_pct)\n",
    "        test_rows = num_rows - train_rows - val_rows\n",
    "\n",
    "        # Split the data into sets\n",
    "        self.train_df = shuffled_df.iloc[:train_rows]\n",
    "        self.val_df = shuffled_df.iloc[train_rows:train_rows+val_rows]\n",
    "        self.test_df = shuffled_df.iloc[train_rows+val_rows:]\n",
    "        \n",
    "        # Add duplicates to training set\n",
    "        self.train_df = pd.concat([self.train_df, self.duplicates])\n",
    "        \n",
    "        # Ensure no overlap in names\n",
    "        train_names = set(self.train_df['name'])\n",
    "        val_names = set(self.val_df['name'])\n",
    "        test_names = set(self.test_df['name'])\n",
    "        \n",
    "        assert len(train_names.intersection(val_names)) == 0, \"Overlap in names between train and validation sets\"\n",
    "        assert len(train_names.intersection(test_names)) == 0, \"Overlap in names between train and test sets\"\n",
    "        assert len(val_names.intersection(test_names)) == 0, \"Overlap in names between validation and test sets\"\n",
    "        \n",
    "    def process_data(self, cols_to_drop):\n",
    "        \n",
    "        self.drop_unknown_users()\n",
    "        self.replace_blank_user_description()\n",
    "        self.drop_columns(cols_to_drop)\n",
    "        self.isolate_duplicates()\n",
    "        self.split_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08258ca6-8cdf-4b12-93bc-9cb70d7d6393",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = DataProcessor(df)\n",
    "cols_to_drop = [\"tweet_coord\", \"user_timezone\", \"tweet_location\", \"unit_id\"]\n",
    "processor.process_data(cols_to_drop)\n",
    "# create train, validation and test\n",
    "train_df = processor.train_df\n",
    "validation_df = processor.val_df\n",
    "test_df = processor.test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f322c757-d7d4-4643-9ca2-34aa2fe71b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9747ef8a9cb84bc698a5d5469a98114e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d7f364fe1f4df0b689543f08f96e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01827b958a046b1964532ddfb0d6310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1a72d59158409d99815fec92c1244f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73cca073f5fd462d9d7e30212fb36799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d19ff5f12d4518b09c25cf9b695c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f742a2d41f5d4e9da8cc81d62b1c0637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d30a39bcbd104d90afcb52344d3b9cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a986ff9c9314823a692e64250dfeed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eadb6aa011c2475b82bb6f9ebd1c0c98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d66535b1cc24ebb9f4405a9b20c7f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6694daa56e11462da0c4ba7c3cdd0bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run profiling reports for data prep steps\n",
    "profile_train = ProfileReport(train_df, title=\"Training Data: twitter profile report\")\n",
    "profile_train.to_file(r\"C:\\Users\\johna\\anaconda3\\envs\\twitter-env-1\\Reports\\Training Data-twitter profile report.html\")\n",
    "\n",
    "profile_validation = ProfileReport(validation_df, title=\"Validation Data: twitter profile report\")\n",
    "profile_validation.to_file(r\"C:\\Users\\johna\\anaconda3\\envs\\twitter-env-1\\Reports\\Validation Data-twitter profile report.html\")\n",
    "\n",
    "profile_test = ProfileReport(test_df, title=\"Test Data: twitter profile report\")\n",
    "profile_test.to_file(r\"C:\\Users\\johna\\anaconda3\\envs\\twitter-env-1\\Reports\\Test Data-twitter profile report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d19dcff9-c555-406a-8fc5-ffdf855f6217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4186ed9d352d453db2db2dcb07a13f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a299a9b550b4bac9d7fce4e0d0ed14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c0ef0616b94e24a41eaaf71276b272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de2f2a7fefb40b6a8735f833e7dd3ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a7839abf27b4dd0bffd8c49c760f737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075cf0d7ddae4d53a3a5c0dd128191b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff0317ec5b5452680bc270d02da21c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fbf3d22ee304e17a6a11e41ea55e676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d537f80364fe4f73939120eff8c88a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate comparison reports\n",
    "comparison_train_val = profile_train.compare(profile_validation)\n",
    "comparison_train_val.to_file(r\"C:\\Users\\johna\\anaconda3\\envs\\twitter-env-1\\Reports\\Comparison-train_vs_validation.html\")\n",
    "\n",
    "comparison_train_test = profile_train.compare(profile_test)\n",
    "comparison_train_test.to_file(r\"C:\\Users\\johna\\anaconda3\\envs\\twitter-env-1\\Reports\\Comparison-train_vs_test.html\")\n",
    "\n",
    "comparison_val_test = profile_validation.compare(profile_test)\n",
    "comparison_val_test.to_file(r\"C:\\Users\\johna\\anaconda3\\envs\\twitter-env-1\\Reports\\Comparison-val_vs_test.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07e62c89-2ba8-40c9-b03d-366b82bb2aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels and features\n",
    "\n",
    "def features_labels(df, label, feature):\n",
    "    y = list(df[label].astype(\"category\").cat.codes)\n",
    "    X = list((df[feature]))\n",
    "    return y, X\n",
    "\n",
    "train_labels, train_user_description = features_labels(train_df, label=\"gender\", feature=\"user_description\")\n",
    "validation_labels, validation_user_description = features_labels(validation_df, label=\"gender\", feature=\"user_description\")\n",
    "test_labels, test_user_description = features_labels(test_df, label=\"gender\", feature=\"user_description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abd8e050-6e2b-443c-b832-79eeb9370ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-multilingual-cased')\n",
    "\n",
    "train_encodings = tokenizer(train_user_description, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(validation_user_description, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_user_description, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e124202-775e-4d07-af9d-a75c25328813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset object\n",
    "\n",
    "import torch\n",
    "\n",
    "class TwitterDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = TwitterDataset(train_encodings, train_labels)\n",
    "validation_dataset = TwitterDataset(val_encodings, validation_labels)\n",
    "test_dataset = TwitterDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2092ef6-8595-45bc-a2eb-252e8e620e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='2592' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   3/2592 01:31 < 65:53:35, 0.01 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13324\\181749392.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[0;32m   1298\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m                             \u001b[1;31m# Revert to normal clipping otherwise, handling Apex or full precision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1300\u001b[1;33m                             torch.nn.utils.clip_grad_norm_(\n\u001b[0m\u001b[0;32m   1301\u001b[0m                                 \u001b[0mamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaster_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_apex\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1302\u001b[0m                                 \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[1;34m(parameters, max_norm, norm_type, error_if_nonfinite)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnorms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mtotal_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merror_if_nonfinite\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         raise RuntimeError(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnorms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mtotal_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merror_if_nonfinite\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         raise RuntimeError(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=r'C:\\Users\\johna\\anaconda3\\envs\\twitter-env-1\\Data\\Model Training Results',          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir=r'C:\\Users\\johna\\anaconda3\\envs\\twitter-env-1\\Data\\Model Training Logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-multilingual-cased\", num_labels=3)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated  Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=validation_dataset      # evaluation dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9334230a-35ac-46b5-bc17-53d5b78c37a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88db4616-66b3-4cd5-a14d-2082a61be87a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
